{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(class_probabilities):\n",
    "    \"\"\"given list of class probs p_i, compute entropy\"\"\"\n",
    "    return sum(-p * math.log(p, 2)\n",
    "              for p in class_probabilities\n",
    "              if p)\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count\n",
    "           for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probabilities = class_probabilities(labels)\n",
    "    return entropy(probabilities)\n",
    "    \n",
    "# partition entropy is the weighted sum of each individual entropy\n",
    "def partition_entropy(subsets):\n",
    "    \"\"\"computes the entropy across all subsets (list of lists)\"\"\"\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    \n",
    "    return sum(len(subset) * data_entropy(subset) / total_count\n",
    "              for subset in subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = [\n",
    "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'no'},   False),\n",
    "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'yes'},  False),\n",
    "        ({'level':'Mid','lang':'Python','tweets':'no','phd':'no'},     True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'no'},  True),\n",
    "        ({'level':'Junior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'R','tweets':'yes','phd':'yes'},    False),\n",
    "        ({'level':'Mid','lang':'R','tweets':'yes','phd':'yes'},        True),\n",
    "        ({'level':'Senior','lang':'Python','tweets':'no','phd':'no'}, False),\n",
    "        ({'level':'Senior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'yes','phd':'no'}, True),\n",
    "        ({'level':'Senior','lang':'Python','tweets':'yes','phd':'yes'},True),\n",
    "        ({'level':'Mid','lang':'Python','tweets':'no','phd':'yes'},    True),\n",
    "        ({'level':'Mid','lang':'Java','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'yes'},False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3\n",
    "\n",
    "1. If all data has same label make a leaf node with that label and stop\n",
    "2. If list of attributes is empy make a leaf node with mode of labels and stop\n",
    "3. Otherwise, partition by all attributes\n",
    "4. Choose partition with lowest entropy\n",
    "5. Add a decision node based on that attribute\n",
    "6. Repeat with other attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_by(inputs, attribute):\n",
    "    \"\"\"input is pair (attr_dict, label)\n",
    "    returns dict: attr_value -> inputs\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for input in inputs:\n",
    "        key = input[0][attribute] # key on value of given attribute\n",
    "        groups[key].append(input) # add the input to this list\n",
    "    return groups\n",
    "\n",
    "def partition_entropy_by(inputs, attribute):\n",
    "    \"\"\"computes total entropy for a given attribute partitioning\"\"\"\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    return partition_entropy(partitions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0.693536138896\n",
      "lang 0.860131712855\n",
      "tweets 0.788450457308\n",
      "phd 0.892158928262\n"
     ]
    }
   ],
   "source": [
    "for key in ['level','lang','tweets','phd']:\n",
    "    print key, partition_entropy_by(inputs, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lang 0.4\n",
      "tweets 0.0\n",
      "phd 0.950977500433\n"
     ]
    }
   ],
   "source": [
    "# split on level\n",
    "senior_inputs = [(input, label)\n",
    "                for input, label in inputs if input['level'] == 'Senior']\n",
    "\n",
    "for key in ['lang','tweets','phd']:\n",
    "    print key, partition_entropy_by(senior_inputs, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, input):\n",
    "    \"\"\"classify the input using the given decision tree\"\"\"\n",
    "    \n",
    "    # if it's a leaf node just spit out value\n",
    "    if tree in [True, False]:\n",
    "        return tree\n",
    "    \n",
    "    # otherwise this has an attr to split\n",
    "    attribute, subtree_dict = tree\n",
    "    \n",
    "    subtree_key = input.get(attribute) # None if missing\n",
    "    \n",
    "    if subtree_key not in subtree_dict: # no tree for this key\n",
    "        subtree_key = None\n",
    "        \n",
    "    subtree = subtree_dict[subtree_key] # get the right subtree\n",
    "    \n",
    "    return classify(subtree, input)\n",
    "\n",
    "\n",
    "def build_tree_id3(inputs, split_candidates = None):\n",
    "    \n",
    "    if split_candidates is None: # first time through\n",
    "        split_candidates = inputs[0][0].keys() # all keys are possible\n",
    "        \n",
    "    # Find all the True False\n",
    "    num_inputs = len(inputs)\n",
    "    num_trues = len([label for item, label in inputs if label])\n",
    "    num_falses = num_inputs - num_trues\n",
    "    \n",
    "    # Step 1) if pure then return label\n",
    "    if num_trues == 0:\n",
    "        return False\n",
    "    if num_falses == 0:\n",
    "        return True\n",
    "    \n",
    "    # Step 2) if we have no candidates left return majority vote\n",
    "    if not split_candidates:\n",
    "        return num_trues >= num_falses\n",
    "    \n",
    "    # Step 3) start recurse\n",
    "    # find best split\n",
    "    best_attribute = min(split_candidates,\n",
    "                        key = partial(partition_entropy_by, inputs))\n",
    "    \n",
    "    # split on that\n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    # remove this attr from the candidates\n",
    "    new_candidates = [a for a in split_candidates\n",
    "                     if a != best_attribute]\n",
    "    \n",
    "    # recurse\n",
    "    subtrees = {attribute_value : build_tree_id3(subset, new_candidates)\n",
    "               for attribute_value, subset in partitions.iteritems()}\n",
    "    \n",
    "    subtrees[None] = num_trues > num_falses # default case of missing value\n",
    "    \n",
    "    return (best_attribute, subtrees)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = build_tree_id3(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('level',\n",
       " {None: True,\n",
       "  'Junior': ('phd', {None: True, 'no': True, 'yes': False}),\n",
       "  'Mid': True,\n",
       "  'Senior': ('tweets', {None: False, 'no': False, 'yes': True})})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(tree, {'level' : 'Junior',\n",
    "               'lang' : 'Java',\n",
    "               'tweets' : 'yes',\n",
    "               'phd' : 'no'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "* Instead of training on all data you train on a bootstrap sample\n",
    "* Instead of choosing all attributes to split you choose a random subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
